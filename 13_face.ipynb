{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼굴 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='images/nmixx.webp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[761,  89,  86,  86],\n",
      "       [569,  76, 128, 128],\n",
      "       [281,  58, 158, 158],\n",
      "       [139,  71, 146, 146],\n",
      "       [414,  61, 161, 161],\n",
      "       [731, 322,  51,  51]], dtype=int32), array([16, 64, 49, 25, 13,  7], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('cascade/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('cascade/haarcascade_eye.xml')\n",
    "img = cv2.imread(path)\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale2(\n",
    "        img_gray, scaleFactor=1.1, minNeighbors=5, minSize=(20, 20)\n",
    "    )\n",
    "eyes = eye_cascade.detectMultiScale(img_gray,1.1,4)\n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m faces \u001b[38;5;241m=\u001b[39m face_cascade\u001b[38;5;241m.\u001b[39mdetectMultiScale2(\n\u001b[1;32m      7\u001b[0m         img_gray, scaleFactor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.1\u001b[39m, minNeighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, minSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m eyes \u001b[38;5;241m=\u001b[39m eye_cascade\u001b[38;5;241m.\u001b[39mdetectMultiScale(img_gray,\u001b[38;5;241m1.1\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x,y,w,h) \u001b[38;5;129;01min\u001b[39;00m faces:\n\u001b[1;32m     11\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mrectangle(img,(x,y),(x\u001b[38;5;241m+\u001b[39mw,y\u001b[38;5;241m+\u001b[39mh),(\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m),\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eyes):\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('cascade/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('cascade/haarcascade_eye.xml')\n",
    "img = cv2.imread(path)\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale2(\n",
    "        img_gray, scaleFactor=1.1, minNeighbors=5, minSize=(20, 20)\n",
    "    )\n",
    "eyes = eye_cascade.detectMultiScale(img_gray,1.1,4)\n",
    "print(faces)\n",
    "for (x,y,w,h) in faces:\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "if len(eyes):\n",
    "    for (x,y,w,h) in eyes:\n",
    "        img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "cv2.imshow('face',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[964  78 882 882]] [47]\n",
      "[[962  75 875 875]] [46]\n",
      "[[964  78 851 851]] [46]\n",
      "[[951  75 861 861]] [44]\n",
      "[[944  75 869 869]] [42]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 10:48:52.514 Python[66294:32485217] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-01-08 10:48:52.514 Python[66294:32485217] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[934  64 879 879]] [43]\n",
      "[[935  70 857 857]] [44]\n",
      "[[917  68 871 871]] [43]\n",
      "[[920  69 861 861]] [49]\n",
      "[[908  68 884 884]] [45]\n",
      "[[909  75 865 865]] [41]\n",
      "[[895  69 874 874]] [41]\n",
      "[[898  68 885 885]] [43]\n",
      "[[897  84 872 872]] [44]\n",
      "[[889  81 886 886]] [45]\n",
      "[[872  82 917 917]] [47]\n",
      "[[877  87 925 925]] [55]\n",
      "[[868 101 917 917]] [48]\n",
      "[[861 109 923 923]] [50]\n",
      "[[854 114 938 938]] [57]\n",
      "[[863 119 931 931]] [53]\n",
      "[[883 127 914 914]] [51]\n",
      "[[880 132 911 911]] [55]\n",
      "[[880 131 910 910]] [51]\n",
      "[[884 123 927 927]] [57]\n",
      "[[876 110 950 950]] [53]\n",
      "[[895 107 944 944]] [47]\n",
      "[[914 117 913 913]] [50]\n",
      "[[923 114 898 898]] [51]\n",
      "[[927 102 922 922]] [53]\n",
      "[[939  93 915 915]] [43]\n",
      "[[960  91 908 908]] [45]\n",
      "[[971  87 907 907]] [48]\n",
      "[[976  93 905 905]] [63]\n",
      "[[999  89 893 893]] [56]\n",
      "[[1008   84  902  902]] [53]\n",
      "[[1022   80  891  891]] [46]\n",
      "[[1044   86  888  888]] [48]\n",
      "[[1037   76  920  920]] [49]\n",
      "[[1051   82  893  893]] [55]\n",
      "[[1072   83  890  890]] [47]\n",
      "[[1072   69  918  918]] [45]\n",
      "[[1087   69  907  907]] [45]\n",
      "[[1082   74  919  919]] [51]\n",
      "[[1095   69  937  937]] [46]\n",
      "[[1110   70  925  925]] [47]\n",
      "[[1129   81  914  914]] [58]\n",
      "[[1136   88  902  902]] [58]\n",
      "[[1140   90  927  927]] [52]\n",
      "[[1142   98  946  946]] [66]\n",
      "[[1154  100  947  947]] [61]\n",
      "[[1160  106  957  957]] [60]\n",
      "[[1188  129  913  913]] [59]\n",
      "[[1195  143  921  921]] [63]\n",
      "[[1181  123  984  984]] [63]\n",
      "[[1207  143  946  946]] [63]\n",
      "[[1216  140  958  958]] [62]\n",
      "[[1216  135  972  972]] [67]\n",
      "[[1231  149  953  953]] [61]\n",
      "[[1250  144  957  957]] [66]\n",
      "[[1249  145  962  962]] [64]\n",
      "[[1254  133  982  982]] [54]\n",
      "[[1272  137  962  962]] [60]\n",
      "[[1272  135  961  961]] [57]\n",
      "[[1285  135  945  945]] [50]\n",
      "[[1288  124  946  946]] [51]\n",
      "[[1307  123  929  929]] [53]\n",
      "[[1308  115  925  925]] [48]\n",
      "[[1316  114  908  908]] [44]\n",
      "[[1320  102  919  919]] [50]\n",
      "[[1312   89  935  935]] [43]\n",
      "[[1317   91  918  918]] [51]\n",
      "[[1314   81  932  932]] [46]\n",
      "[[1320   78  910  910]] [45]\n",
      "[[1329   76  904  904]] [45]\n",
      "[[1335   74  881  881]] [47]\n",
      "[[1330   72  884  884]] [38]\n",
      "[[1334   69  883  883]] [39]\n",
      "[[1333   73  885  885]] [43]\n",
      "[[1329   68  884  884]] [43]\n",
      "[[1336   72  882  882]] [39]\n",
      "[[1335   73  891  891]] [37]\n",
      "[[1335   76  897  897]] [40]\n",
      "[[1331   73  920  920]] [44]\n",
      "[[1341   94  898  898]] [48]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = 'video/face.mp4'\n",
    "cap = cv2.VideoCapture(video)\n",
    "face_cascade = cv2.CascadeClassifier('cascade/haarcascade_frontalface_default.xml')\n",
    "if not cap.isOpened():\n",
    "    exit()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    frame_gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces, weights_face= face_cascade.detectMultiScale2(\n",
    "        frame_gray, scaleFactor=1.1, minNeighbors=5, minSize=(20, 20)\n",
    "    )\n",
    "    print(faces,weights_face)\n",
    "    if not ret:\n",
    "        break\n",
    "    for (x,y,w,h) in faces:\n",
    "        frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "    \n",
    "    cv2.imshow('camera',frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 - 캠 얼굴 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 11:14:16.449 Python[67449:32509205] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-01-08 11:14:16.449 Python[67449:32509205] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n",
      "2025-01-08 11:14:20.158 Python[67449:32509205] error messaging the mach port for IMKCFRunLoopWakeUpReliable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier('cascade/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('cascade/haarcascade_eye.xml')\n",
    "if not cap.isOpened():\n",
    "    exit()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(frame_gray,1.3,10)\n",
    "    \n",
    "    eyes = eye_cascade.detectMultiScale(frame_gray,1.1,8)\n",
    "    for (x,y,w,h) in faces:\n",
    "        frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "        frame = cv2.putText(frame, \"face\", ((2*x+w)//2,y), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,0,0),3)\n",
    "    for (x,y,w,h) in eyes:\n",
    "        frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "        frame = cv2.putText(frame, \"eye\", ((2*x+w)//2,y), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "             2, (255,0,0),3)\n",
    "    cv2.imshow('camera',frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('cascade/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('cascade/haarcascade_eye.xml')\n",
    "if not cap.isOpened():\n",
    "    exit()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces, weights_face= face_cascade.detectMultiScale2(\n",
    "        frame_gray, scaleFactor=1.1, minNeighbors=5, minSize=(20, 20)\n",
    "    )\n",
    "    eyes,weights_eye = eye_cascade.detectMultiScale2(frame_gray, scaleFactor=1.1, minNeighbors=5, minSize=(20, 20)\n",
    "    )\n",
    "    \n",
    "    for (face,weight) in zip(faces,weights_face):\n",
    "        x,y,w,h = face\n",
    "        \n",
    "        frame = cv2.putText(frame, f\"face, score: {weight}\", ((2*x+w)//2,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0),3)\n",
    "    for (eye, weight) in zip(eyes,weights_eye):\n",
    "        x,y,w,h = eye\n",
    "        frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "        frame = cv2.putText(frame, f\"eye, score :{weight}\", ((2*x+w)//2,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0),3)\n",
    "    cv2.imshow('camera',frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 2 사진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "img = cv2.imread('images/nmixx.webp')\n",
    "left = cv2.imread('images/left_eye.jpg')\n",
    "right = cv2.imread('images/right_eye.jpg')\n",
    "face_cascade = cv2.CascadeClassifier('cascade/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('cascade/haarcascade_eye.xml')\n",
    "\n",
    "img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(img_gray,1.5,2)\n",
    "eyes = eye_cascade.detectMultiScale(img_gray,1.5,1)\n",
    "    \n",
    "for x,y,w,h in faces:\n",
    "    for x_e,y_e,w_e,h_e in eyes:\n",
    "        if x <= x_e<= x+w and y <=y_e<=y+h: \n",
    "                if x_e < (x+w/2) :\n",
    "                    dst_left = cv2.resize(left, (w_e, h_e), interpolation=cv2.INTER_LANCZOS4)\n",
    "                    img[y_e:y_e+h_e,x_e:x_e+w_e] = dst_left\n",
    "                else :\n",
    "                    dst_right = cv2.resize(right, (w_e, h_e), interpolation=cv2.INTER_LANCZOS4)\n",
    "                    img[y_e:y_e+h_e,x_e:x_e+w_e] = dst_right\n",
    "cv2.imshow('camera',img)\n",
    "    \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹캠 영상에 눈 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "left = cv2.imread('images/left_eye.jpg')\n",
    "right = cv2.imread('images/right_eye.jpg')\n",
    "face_cascade = cv2.CascadeClassifier('cascade/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('cascade/haarcascade_eye.xml')\n",
    "if not cap.isOpened():\n",
    "    exit()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(frame_gray,1.3,10)\n",
    "    eyes = eye_cascade.detectMultiScale(frame_gray,1.1,8)\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        for x_e,y_e,w_e,h_e in eyes:\n",
    "            if x <= x_e<= x+w and y <=y_e<=y+h:\n",
    "                if x_e < (x+w/2) :\n",
    "                    dst_left = cv2.resize(left, (w_e, h_e), interpolation=cv2.INTER_LANCZOS4)\n",
    "                    frame[y_e:y_e+h_e,x_e:x_e+w_e] = dst_left\n",
    "                else :\n",
    "                    dst_right = cv2.resize(right, (w_e, h_e), interpolation=cv2.INTER_LANCZOS4)\n",
    "                    frame[y_e:y_e+h_e,x_e:x_e+w_e] = dst_right\n",
    "    cv2.imshow('camera',frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
